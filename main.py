# é€šè¿‡è¿™ä¸ªä¸»å‡½æ•°å®ç°æ¯æ—¥AIå…¬ä¼—å·é€Ÿè§ˆ

from wechat_ai_daily.workflows import DailyGenerator, RPAArticleCollector, APIArticleCollector, DailyPublisher
from datetime import datetime, date
import logging
import asyncio
import argparse
from pathlib import Path
from ruamel.yaml import YAML

# åŠ è½½ .env ç¯å¢ƒå˜é‡ï¼ˆå¿…é¡»åœ¨å…¶ä»–æ¨¡å—å¯¼å…¥å‰è°ƒç”¨ï¼‰
from wechat_ai_daily.utils.env_loader import load_env
load_env()


# ç¡®ä¿ logs ç›®å½•å­˜åœ¨
Path("logs").mkdir(exist_ok=True)

# é…ç½®æ—¥å¿—ç³»ç»Ÿ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),  # è¾“å‡ºåˆ°æ§åˆ¶å°
        logging.FileHandler("logs/main.log", encoding="utf-8")  # è¾“å‡ºåˆ°æ–‡ä»¶
    ],
    force=True  # å¼ºåˆ¶é‡æ–°é…ç½®ï¼Œè¦†ç›–ä¹‹å‰çš„é…ç½®
)

# ç¡®ä¿æ ¹æ—¥å¿—è®°å½•å™¨çš„çº§åˆ«æ˜¯ INFO
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# åŒæ—¶ç¡®ä¿æ‰€æœ‰ handler çš„çº§åˆ«ä¹Ÿæ˜¯ INFO
for handler in logger.handlers:
    handler.setLevel(logging.INFO)


def print_legal_notice():
    """æ‰“å°æ³•å¾‹å£°æ˜ï¼ˆä½¿ç”¨ logging.warning å±‚çº§ï¼‰"""
    logging.warning("=" * 70)
    logging.warning("âš ï¸  æ³•å¾‹å£°æ˜")
    logging.warning("=" * 70)
    logging.warning("æœ¬å·¥å…·ä»…ä¾›ä¸ªäººå­¦ä¹ å’Œç ”ç©¶ä½¿ç”¨ï¼Œè¯·å‹¿ç”¨äºå•†ä¸šç›®çš„ã€‚")
    logging.warning("")
    logging.warning("ã€é£é™©æç¤ºã€‘")
    logging.warning("â€¢ API æ¨¡å¼ä½¿ç”¨äº†å¾®ä¿¡å…¬ä¼—å¹³å°çš„éå…¬å¼€åå°æ¥å£ï¼Œå¯èƒ½è¿åå¹³å°æœåŠ¡åè®®")
    logging.warning("â€¢ RPA æ¨¡å¼çš„ GUI è‡ªåŠ¨åŒ–æ“ä½œå¯èƒ½è¿åå¾®ä¿¡ç”¨æˆ·åè®®")
    logging.warning("â€¢ ä½¿ç”¨æœ¬å·¥å…·äº§ç”Ÿçš„ä¸€åˆ‡åæœç”±ä½¿ç”¨è€…è‡ªè¡Œæ‰¿æ‹…")
    logging.warning("")
    logging.warning("ç»§ç»­ä½¿ç”¨å³è¡¨ç¤ºæ‚¨å·²é˜…è¯»å¹¶åŒæ„éµå®ˆç›¸å…³å£°æ˜ã€‚")
    logging.warning("è¯¦ç»†æ¡æ¬¾è¯·æŸ¥çœ‹ LICENSE æ–‡ä»¶å’Œ README.md ä¸­çš„æ³•å¾‹å£°æ˜éƒ¨åˆ†ã€‚")
    logging.warning("=" * 70)


def parse_target_date(config_path: str = "configs/config.yaml") -> datetime:
    """è§£æé…ç½®æ–‡ä»¶ä¸­çš„ç›®æ ‡æ—¥æœŸï¼ˆRPA æ¨¡å¼ä¸“ç”¨ï¼‰

    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„

    Returns:
        datetime: è§£æåçš„ç›®æ ‡æ—¥æœŸ
    """
    try:
        yaml = YAML()
        with open(config_path, "r", encoding="utf-8") as f:
            config = yaml.load(f) or {}
    except Exception as e:
        logging.warning(f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}ï¼Œä½¿ç”¨å½“å¤©æ—¥æœŸ")
        return datetime.now()

    target_date_str = config.get("target_date")

    # null è¡¨ç¤ºå½“å¤©
    if target_date_str is None:
        return datetime.now()

    # å¦‚æœ YAML å·²ç»è§£æä¸º date/datetime å¯¹è±¡ï¼Œç›´æ¥è½¬æ¢
    if isinstance(target_date_str, datetime):
        return target_date_str
    if isinstance(target_date_str, date):
        return datetime.combine(target_date_str, datetime.min.time())

    # å°è¯•è§£æå…·ä½“æ—¥æœŸå­—ç¬¦ä¸²ï¼ˆæ ¼å¼ï¼šYYYY-MM-DDï¼‰
    try:
        return datetime.strptime(target_date_str, "%Y-%m-%d")
    except ValueError:
        logging.warning(f"æ— æ³•è§£ææ—¥æœŸ '{target_date_str}'ï¼Œä½¿ç”¨å½“å¤©æ—¥æœŸ")
        return datetime.now()


def parse_date_range(config_path: str = "configs/config.yaml") -> tuple[datetime, datetime]:
    """è§£æé…ç½®æ–‡ä»¶ä¸­çš„æ—¶é—´èŒƒå›´ï¼ˆAPI æ¨¡å¼ä¸“ç”¨ï¼‰

    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„

    Returns:
        tuple[datetime, datetime]: (å¼€å§‹æ—¶é—´, ç»“æŸæ—¶é—´) å…ƒç»„
    """
    try:
        yaml = YAML()
        with open(config_path, "r", encoding="utf-8") as f:
            config = yaml.load(f) or {}
    except Exception as e:
        logging.warning(f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}ï¼Œä½¿ç”¨å½“å¤©æ—¶é—´èŒƒå›´")
        today = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)
        return today, today.replace(hour=23, minute=59)

    start_date_str = config.get("start_date")
    end_date_str = config.get("end_date")

    # è§£æå¼€å§‹æ—¶é—´
    start_date = _parse_datetime_str(start_date_str, "start_date")
    if start_date is None:
        start_date = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)

    # è§£æç»“æŸæ—¶é—´
    end_date = _parse_datetime_str(end_date_str, "end_date")
    if end_date is None:
        end_date = datetime.now().replace(hour=23, minute=59, second=0, microsecond=0)

    # éªŒè¯æ—¶é—´èŒƒå›´
    if start_date > end_date:
        logging.warning(f"å¼€å§‹æ—¶é—´ {start_date} æ™šäºç»“æŸæ—¶é—´ {end_date}ï¼Œè‡ªåŠ¨äº¤æ¢")
        start_date, end_date = end_date, start_date

    return start_date, end_date


def _parse_datetime_str(date_str, field_name: str) -> datetime | None:
    """è§£ææ—¥æœŸæ—¶é—´å­—ç¬¦ä¸²

    æ”¯æŒä¸¤ç§æ ¼å¼ï¼š
    - "YYYY-MM-DD HH:mm" - ç²¾ç¡®åˆ°åˆ†é’Ÿ
    - "YYYY-MM-DD" - ç²¾ç¡®åˆ°å¤©ï¼ˆè‡ªåŠ¨è¡¥å……æ—¶é—´ï¼‰

    Args:
        date_str: æ—¥æœŸæ—¶é—´å­—ç¬¦ä¸²æˆ– datetime/date å¯¹è±¡
        field_name: å­—æ®µåç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰

    Returns:
        datetime | None: è§£æåçš„ datetime å¯¹è±¡ï¼Œè§£æå¤±è´¥è¿”å› None
    """
    if date_str is None:
        return None

    # å¦‚æœ YAML å·²ç»è§£æä¸º datetime å¯¹è±¡
    if isinstance(date_str, datetime):
        return date_str

    # å¦‚æœ YAML å·²ç»è§£æä¸º date å¯¹è±¡
    if isinstance(date_str, date):
        return datetime.combine(date_str, datetime.min.time())

    # å°è¯•è§£æå­—ç¬¦ä¸²
    if isinstance(date_str, str):
        # å°è¯•æ ¼å¼ï¼šYYYY-MM-DD HH:mm
        try:
            return datetime.strptime(date_str, "%Y-%m-%d %H:%M")
        except ValueError:
            pass

        # å°è¯•æ ¼å¼ï¼šYYYY-MM-DD
        try:
            return datetime.strptime(date_str, "%Y-%m-%d")
        except ValueError:
            pass

        logging.warning(
            f"æ— æ³•è§£æ {field_name} '{date_str}'ï¼Œæ ¼å¼åº”ä¸º 'YYYY-MM-DD HH:mm' æˆ– 'YYYY-MM-DD'")

    return None


async def main():
    """ä¸»å‡½æ•°ï¼šæ”¯æŒ RPA/API åŒæ¨¡å¼é‡‡é›†ï¼Œæ”¯æŒå®Œæ•´çš„é‡‡é›†â†’ç”Ÿæˆâ†’å‘å¸ƒå·¥ä½œæµ"""

    # æ˜¾ç¤ºæ³•å¾‹å£°æ˜
    print_legal_notice()

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(
        description="å¾®ä¿¡å…¬ä¼—å·æ–‡ç« æ™ºèƒ½å‘å¸ƒå·¥å…· - æ”¯æŒ RPA/API åŒæ¨¡å¼é‡‡é›†ï¼Œæ”¯æŒå®Œæ•´çš„é‡‡é›†â†’ç”Ÿæˆâ†’å‘å¸ƒå·¥ä½œæµ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹ï¼š
  # ä¸€é”®å…¨æµç¨‹ï¼ˆRPA æ¨¡å¼ï¼‰
  python main.py --mode rpa --workflow full
  
  # ä¸€é”®å…¨æµç¨‹ï¼ˆAPI æ¨¡å¼ï¼Œæ¨èï¼‰
  python main.py --mode api --workflow full
  
  # ä»…é‡‡é›†æ–‡ç« ï¼ˆRPA æ¨¡å¼ï¼‰
  python main.py --mode rpa --workflow collect
  
  # ä»…é‡‡é›†æ–‡ç« ï¼ˆAPI æ¨¡å¼ï¼‰
  python main.py --mode api --workflow collect
  
    # ä»…ç”Ÿæˆå…¬ä¼—å·æ–‡ç« å†…å®¹ï¼ˆéœ€è¦å…ˆæ‰§è¡Œé‡‡é›†ï¼‰
  python main.py --workflow generate --markdown-file output/articles_20260126.md
  
  # ä»…å‘å¸ƒè‰ç¨¿ï¼ˆéœ€è¦å…ˆæ‰§è¡Œç”Ÿæˆï¼‰
  python main.py --workflow publish --html-file output/daily_rich_text_20260126.html
        """
    )

    parser.add_argument(
        "--mode",
        choices=["rpa", "api"],
        default="api",
        help="é‡‡é›†æ¨¡å¼ï¼šrpaï¼ˆGUIè‡ªåŠ¨åŒ–+VLMè¯†åˆ«ï¼‰æˆ– apiï¼ˆå¾®ä¿¡å…¬ä¼—å¹³å°åå°æ¥å£ï¼Œæ¨èï¼‰ã€‚é»˜è®¤: api"
    )

    parser.add_argument(
        "--workflow",
        choices=["collect", "generate", "publish", "full"],
        default="full",
        help="å·¥ä½œæµç±»å‹ï¼šcollectï¼ˆä»…é‡‡é›†ï¼‰ã€generateï¼ˆä»…ç”Ÿæˆï¼‰ã€publishï¼ˆä»…å‘å¸ƒï¼‰ã€fullï¼ˆå®Œæ•´æµç¨‹ï¼‰ã€‚é»˜è®¤: full"
    )

    parser.add_argument(
        "--markdown-file",
        type=str,
        help="æŒ‡å®šå·²æœ‰çš„æ–‡ç« åˆ—è¡¨ Markdown æ–‡ä»¶ï¼ˆç”¨äº generate æˆ– publish å·¥ä½œæµï¼‰ã€‚å¦‚ä¸æŒ‡å®šï¼Œå°†ä½¿ç”¨é‡‡é›†æ­¥éª¤ç”Ÿæˆçš„æ–‡ä»¶"
    )

    parser.add_argument(
        "--html-file",
        type=str,
        help="æŒ‡å®šå·²æœ‰çš„å…¬ä¼—å·æ–‡ç« å†…å®¹ HTML æ–‡ä»¶ï¼ˆç”¨äº publish å·¥ä½œæµï¼‰ã€‚å¦‚ä¸æŒ‡å®šï¼Œå°†ä½¿ç”¨ç”Ÿæˆæ­¥éª¤ç”Ÿæˆçš„æ–‡ä»¶"
    )

    parser.add_argument(
        "--start-date",
        type=str,
        help="å¼€å§‹æ—¶é—´ï¼ˆAPI æ¨¡å¼ä¸“ç”¨ï¼‰ï¼Œæ ¼å¼ 'YYYY-MM-DD HH:mm' æˆ– 'YYYY-MM-DD'ã€‚å¦‚ä¸æŒ‡å®šï¼Œä»é…ç½®æ–‡ä»¶è¯»å–"
    )

    parser.add_argument(
        "--end-date",
        type=str,
        help="ç»“æŸæ—¶é—´ï¼ˆAPI æ¨¡å¼ä¸“ç”¨ï¼‰ï¼Œæ ¼å¼ 'YYYY-MM-DD HH:mm' æˆ– 'YYYY-MM-DD'ã€‚å¦‚ä¸æŒ‡å®šï¼Œä»é…ç½®æ–‡ä»¶è¯»å–"
    )

    args = parser.parse_args()

    # æ ¹æ®æ¨¡å¼è§£ææ—¥æœŸ/æ—¶é—´èŒƒå›´
    if args.mode == "api":
        # API æ¨¡å¼ï¼šä½¿ç”¨æ—¶é—´èŒƒå›´ï¼ˆç²¾ç¡®åˆ°åˆ†é’Ÿï¼‰
        # å‘½ä»¤è¡Œå‚æ•°ä¼˜å…ˆäºé…ç½®æ–‡ä»¶
        if args.start_date:
            start_date = _parse_datetime_str(args.start_date, "start-date")
            if start_date is None:
                logging.error(f"æ— æ³•è§£æ --start-date å‚æ•°: {args.start_date}")
                return
        else:
            start_date = None

        if args.end_date:
            end_date = _parse_datetime_str(args.end_date, "end-date")
            if end_date is None:
                logging.error(f"æ— æ³•è§£æ --end-date å‚æ•°: {args.end_date}")
                return
        else:
            end_date = None

        # å¦‚æœå‘½ä»¤è¡ŒæœªæŒ‡å®šï¼Œä»é…ç½®æ–‡ä»¶è¯»å–
        if start_date is None or end_date is None:
            config_start, config_end = parse_date_range()
            if start_date is None:
                start_date = config_start
            if end_date is None:
                end_date = config_end

        # ç”¨äºåç»­æ­¥éª¤çš„ç›®æ ‡æ—¥æœŸï¼ˆå–å¼€å§‹æ—¥æœŸçš„æ—¥æœŸéƒ¨åˆ†ï¼‰
        target_date = start_date

        logging.info(
            f"æ—¶é—´èŒƒå›´: {start_date.strftime('%Y-%m-%d %H:%M')} ~ {end_date.strftime('%Y-%m-%d %H:%M')}")
    else:
        # RPA æ¨¡å¼ï¼šä½¿ç”¨ç›®æ ‡æ—¥æœŸï¼ˆç²¾ç¡®åˆ°å¤©ï¼‰
        target_date = parse_target_date()
        start_date = None
        end_date = None
        logging.info(f"ç›®æ ‡æ—¥æœŸ: {target_date.strftime('%Y-%m-%d')}")

    logging.info(f"é‡‡é›†æ¨¡å¼: {args.mode.upper()}")
    logging.info(f"å·¥ä½œæµç±»å‹: {args.workflow.upper()}")

    # åˆå§‹åŒ–å˜é‡
    markdown_file = args.markdown_file
    html_file = args.html_file

    # æ­¥éª¤1ï¼šé‡‡é›†å…¬ä¼—å·æ–‡ç« 
    if args.workflow in ["collect", "full"]:
        logging.info("=" * 60)
        logging.info("æ­¥éª¤ 1/3: å¼€å§‹é‡‡é›†å…¬ä¼—å·æ–‡ç« ...")
        logging.info("=" * 60)

        if args.mode == "rpa":
            # RPA æ¨¡å¼ï¼šä½¿ç”¨ RPAArticleCollectorï¼ˆå¼‚æ­¥æ–¹æ³•ï¼‰
            logging.info("ä½¿ç”¨ RPA æ¨¡å¼é‡‡é›†ï¼ˆGUI è‡ªåŠ¨åŒ– + VLM å›¾åƒè¯†åˆ«ï¼‰")
            collector = RPAArticleCollector(config="configs/config.yaml")
            markdown_file = await collector.run()
        else:  # api
            # API æ¨¡å¼ï¼šä½¿ç”¨ APIArticleCollectorï¼ˆåŒæ­¥æ–¹æ³•ï¼‰
            logging.info("ä½¿ç”¨ API æ¨¡å¼é‡‡é›†ï¼ˆå¾®ä¿¡å…¬ä¼—å¹³å°åå°æ¥å£ï¼‰")
            collector = APIArticleCollector(config="configs/config.yaml")
            markdown_file = collector.run()

        logging.info(f"âœ“ æ–‡ç« é‡‡é›†å®Œæˆï¼Œè¾“å‡ºæ–‡ä»¶: {markdown_file}")

    # æ­¥éª¤2ï¼šç”Ÿæˆå…¬ä¼—å·æ–‡ç« å†…å®¹
    if args.workflow in ["generate", "full"]:
        logging.info("=" * 60)
        logging.info("æ­¥éª¤ 2/3: å¼€å§‹ç”Ÿæˆå…¬ä¼—å·æ–‡ç« å†…å®¹...")
        logging.info("=" * 60)

        # æ£€æŸ¥æ˜¯å¦æœ‰ markdown æ–‡ä»¶
        if not markdown_file:
            # å¦‚æœæ²¡æœ‰æŒ‡å®šï¼Œå°è¯•è‡ªåŠ¨æŸ¥æ‰¾å½“å¤©çš„æ–‡ä»¶
            date_str = target_date.strftime("%Y%m%d")
            auto_markdown = f"output/articles_{date_str}.md"
            if Path(auto_markdown).exists():
                markdown_file = auto_markdown
                logging.info(f"è‡ªåŠ¨æ‰¾åˆ°æ–‡ç« åˆ—è¡¨æ–‡ä»¶: {markdown_file}")
            else:
                logging.error(
                    "é”™è¯¯: æœªæ‰¾åˆ°æ–‡ç« åˆ—è¡¨æ–‡ä»¶ã€‚è¯·å…ˆæ‰§è¡Œé‡‡é›†æ­¥éª¤ï¼Œæˆ–ä½¿ç”¨ --markdown-file æŒ‡å®šæ–‡ä»¶è·¯å¾„")
                return

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not Path(markdown_file).exists():
            logging.error(f"é”™è¯¯: æ–‡ç« åˆ—è¡¨æ–‡ä»¶ä¸å­˜åœ¨: {markdown_file}")
            return

        daily_generator = DailyGenerator(config="configs/config.yaml")
        # API æ¨¡å¼æŒ‰â€œæ—¶é—´èŒƒå›´â€è¿‡æ»¤ï¼ŒRPA æ¨¡å¼æŒ‰â€œç›®æ ‡æ—¥æœŸâ€è¿‡æ»¤
        if args.mode == "api":
            html_file = await daily_generator.run(
                markdown_file=markdown_file,
                date=target_date,
                start_time=start_date,
                end_time=end_date
            )
        else:
            html_file = await daily_generator.run(
                markdown_file=markdown_file,
                date=target_date
            )
        logging.info(f"âœ“ å…¬ä¼—å·æ–‡ç« å†…å®¹ç”Ÿæˆå®Œæˆï¼Œè¾“å‡ºæ–‡ä»¶: {html_file}")

    # æ­¥éª¤3ï¼šå‘å¸ƒè‰ç¨¿
    if args.workflow in ["publish", "full"]:
        logging.info("=" * 60)
        logging.info("æ­¥éª¤ 3/3: å¼€å§‹å‘å¸ƒå…¬ä¼—å·è‰ç¨¿...")
        logging.info("=" * 60)

        # æ£€æŸ¥æ˜¯å¦æœ‰ html æ–‡ä»¶
        if not html_file:
            # å¦‚æœæ²¡æœ‰æŒ‡å®šï¼Œå°è¯•è‡ªåŠ¨æŸ¥æ‰¾å½“å¤©çš„æ–‡ä»¶
            date_str = target_date.strftime("%Y%m%d")
            auto_html = f"output/daily_rich_text_{date_str}.html"
            if Path(auto_html).exists():
                html_file = auto_html
                logging.info(f"è‡ªåŠ¨æ‰¾åˆ°å…¬ä¼—å·æ–‡ç« å†…å®¹ HTML æ–‡ä»¶: {html_file}")
            else:
                logging.error(
                    "é”™è¯¯: æœªæ‰¾åˆ°å…¬ä¼—å·æ–‡ç« å†…å®¹ HTML æ–‡ä»¶ã€‚è¯·å…ˆæ‰§è¡Œç”Ÿæˆæ­¥éª¤ï¼Œæˆ–ä½¿ç”¨ --html-file æŒ‡å®šæ–‡ä»¶è·¯å¾„")
                return

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not Path(html_file).exists():
            logging.error(f"é”™è¯¯: å…¬ä¼—å·æ–‡ç« å†…å®¹ HTML æ–‡ä»¶ä¸å­˜åœ¨: {html_file}")
            return

        publisher = DailyPublisher(config="configs/config.yaml")

        # ç”Ÿæˆæ ‡é¢˜ï¼ˆæ ¼å¼ï¼šAIæ—¥æŠ¥ - YYYY-MM-DDï¼‰
        title = f"AIæ—¥æŠ¥ - {target_date.strftime('%Y-%m-%d')}"
        logging.info(f"ä½¿ç”¨æ ‡é¢˜: {title}")

        # DailyPublisher.run() æ˜¯åŒæ­¥æ–¹æ³•ï¼Œå‚æ•°ä¸º html_path, title, digest
        draft_media_id = publisher.run(
            html_path=html_file, title=title, digest="")
        logging.info(f"âœ“ è‰ç¨¿å‘å¸ƒå®Œæˆï¼media_id: {draft_media_id}")
        logging.info("è¯·å‰å¾€å¾®ä¿¡å…¬ä¼—å¹³å°æŸ¥çœ‹è‰ç¨¿")

    logging.info("=" * 60)
    logging.info("ğŸ‰ æ‰€æœ‰ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼")
    logging.info("=" * 60)


if __name__ == "__main__":
    asyncio.run(main())
