"""æµ‹è¯•æ¯æ—¥æ—¥æŠ¥ç”Ÿæˆå™¨å·¥ä½œæµ

è¿™ä¸ªæµ‹è¯•æ–‡ä»¶ç”¨äºæµ‹è¯• DailyGenerator çš„ build_workflow æ˜¯å¦èƒ½æ­£å¸¸è¿è¡Œã€‚
ä½¿ç”¨ output/articles_20260119.md ä½œä¸ºæµ‹è¯•æ•°æ®ã€‚

è¿è¡Œæ–¹å¼:
    uv run pytest tests/test_daily_generate_workflow.py -v -s
    
æˆ–ç›´æ¥è¿è¡Œ:
    uv run python tests/test_daily_generate_workflow.py
"""

import sys
import os
import pytest
import logging
import asyncio
from pathlib import Path
from datetime import datetime

# å°† src ç›®å½•æ·»åŠ åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

# åŠ è½½ .env ç¯å¢ƒå˜é‡
from wechat_ai_daily.utils.env_loader import load_env
load_env()

from wechat_ai_daily.workflows.daily_generate import DailyGenerator


# é…ç½®æ—¥å¿— - ä½¿ç”¨æ›´è¯¦ç»†çš„æ ¼å¼
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
    ]
)
logger = logging.getLogger(__name__)


def print_status(message: str, status: str = "INFO"):
    """æ‰“å°å¸¦çŠ¶æ€çš„ä¿¡æ¯

    Args:
        message: è¦æ˜¾ç¤ºçš„ä¿¡æ¯
        status: çŠ¶æ€ç±»å‹ (INFO, OK, WARN, ERROR, WAIT)
    """
    icons = {
        "INFO": "â„¹ï¸ ",
        "OK": "âœ…",
        "WARN": "âš ï¸ ",
        "ERROR": "âŒ",
        "WAIT": "â³",
        "START": "ğŸš€",
        "END": "ğŸ",
    }
    icon = icons.get(status, "")
    timestamp = datetime.now().strftime("%H:%M:%S")
    print(f"[{timestamp}] {icon} {message}", flush=True)


@pytest.fixture
def test_markdown_file():
    """æµ‹è¯•æ•°æ®æ–‡ä»¶è·¯å¾„"""
    project_root = Path(__file__).parent.parent
    markdown_file = project_root / "output" / "articles_20260119.md"

    assert markdown_file.exists(), f"æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {markdown_file}"

    return str(markdown_file)


@pytest.fixture
def daily_generator():
    """åˆ›å»º DailyGenerator å®ä¾‹"""
    api_key = os.getenv("DASHSCOPE_API_KEY")
    if not api_key:
        pytest.skip("æœªè®¾ç½® DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡ï¼Œè·³è¿‡æµ‹è¯•")

    generator = DailyGenerator(
        model="qwen-plus",
        enable_thinking=True,
        thinking_budget=1024,
        max_retries=2
    )

    return generator


def test_parse_article_urls(daily_generator, test_markdown_file):
    """æµ‹è¯•è§£ææ–‡ç« é“¾æ¥åŠŸèƒ½"""
    print_status("å¼€å§‹æµ‹è¯•: è§£ææ–‡ç« é“¾æ¥", "START")

    urls = daily_generator._parse_article_urls(test_markdown_file)

    assert len(urls) > 0, "åº”è¯¥è§£æåˆ°è‡³å°‘ä¸€ä¸ªé“¾æ¥"
    print_status(f"æˆåŠŸè§£æåˆ° {len(urls)} ä¸ªæ–‡ç« é“¾æ¥", "OK")

    for i, url in enumerate(urls, 1):
        assert url.startswith("https://mp.weixin.qq.com/s/"), f"é“¾æ¥æ ¼å¼ä¸æ­£ç¡®: {url}"
        print_status(f"  {i}. {url}", "INFO")

    print_status("æ–‡ç« é“¾æ¥è§£ææµ‹è¯•é€šè¿‡", "OK")


@pytest.mark.asyncio
async def test_get_html_content(daily_generator, test_markdown_file):
    """æµ‹è¯•è·å–HTMLå†…å®¹åŠŸèƒ½"""
    print_status("å¼€å§‹æµ‹è¯•: è·å–HTMLå†…å®¹", "START")

    urls = daily_generator._parse_article_urls(test_markdown_file)
    assert len(urls) > 0, "éœ€è¦è‡³å°‘ä¸€ä¸ªæµ‹è¯•é“¾æ¥"

    test_url = urls[0]
    print_status(f"æµ‹è¯•é“¾æ¥: {test_url}", "INFO")
    print_status("æ­£åœ¨è·å–HTMLå†…å®¹ï¼ˆå¯èƒ½éœ€è¦å‡ ç§’é’Ÿï¼‰...", "WAIT")

    html_content = daily_generator._get_html_content(test_url)

    assert len(html_content) > 0, "HTMLå†…å®¹ä¸åº”ä¸ºç©º"
    print_status(f"æˆåŠŸè·å–HTMLå†…å®¹ï¼Œé•¿åº¦: {len(html_content)} å­—ç¬¦", "OK")


@pytest.mark.asyncio
async def test_extract_article_metadata(daily_generator, test_markdown_file):
    """æµ‹è¯•æå–æ–‡ç« å…ƒæ•°æ®åŠŸèƒ½"""
    print_status("å¼€å§‹æµ‹è¯•: æå–æ–‡ç« å…ƒæ•°æ®", "START")

    urls = daily_generator._parse_article_urls(test_markdown_file)
    test_url = urls[0]

    print_status("æ­£åœ¨è·å–HTMLå†…å®¹...", "WAIT")
    html_content = daily_generator._get_html_content(test_url)

    print_status("æ­£åœ¨æå–å…ƒæ•°æ®...", "WAIT")
    metadata = daily_generator._extract_article_metadata(
        html_content, test_url)

    assert metadata.title, "æ ‡é¢˜ä¸åº”ä¸ºç©º"
    assert metadata.article_url == test_url, "URLåº”è¯¥åŒ¹é…"

    print_status(f"æ–‡ç« æ ‡é¢˜: {metadata.title}", "INFO")
    print_status(f"å…¬ä¼—å·åç§°: {metadata.account_name}", "INFO")
    print_status(f"å‘å¸ƒæ—¶é—´: {metadata.publish_time}", "INFO")
    print_status(f"æ­£æ–‡é•¿åº¦: {len(metadata.content)} å­—ç¬¦", "INFO")

    print_status("æ–‡ç« å…ƒæ•°æ®æå–æµ‹è¯•é€šè¿‡", "OK")


@pytest.mark.asyncio
async def test_generate_article_summary(daily_generator, test_markdown_file):
    """æµ‹è¯•ç”Ÿæˆæ–‡ç« æ‘˜è¦åŠŸèƒ½ï¼ˆè°ƒç”¨LLMï¼Œè€—æ—¶è¾ƒé•¿ï¼‰"""
    print_status("å¼€å§‹æµ‹è¯•: ç”Ÿæˆæ–‡ç« æ‘˜è¦", "START")
    print_status("âš ï¸  æ­¤æµ‹è¯•ä¼šè°ƒç”¨LLM APIï¼Œå¯èƒ½éœ€è¦30-60ç§’ï¼Œè¯·è€å¿ƒç­‰å¾…...", "WARN")

    urls = daily_generator._parse_article_urls(test_markdown_file)
    test_url = urls[0]

    print_status("æ­£åœ¨è·å–HTMLå†…å®¹...", "WAIT")
    html_content = daily_generator._get_html_content(test_url)

    print_status("æ­£åœ¨æå–å…ƒæ•°æ®...", "WAIT")
    metadata = daily_generator._extract_article_metadata(
        html_content, test_url)
    print_status(f"æ–‡ç« : {metadata.title}", "INFO")

    print_status("æ­£åœ¨è°ƒç”¨LLMç”Ÿæˆæ‘˜è¦ï¼ˆè¿™ä¸€æ­¥æ¯”è¾ƒè€—æ—¶ï¼‰...", "WAIT")
    start_time = datetime.now()

    summary = await daily_generator._generate_article_summary(metadata)

    elapsed = (datetime.now() - start_time).total_seconds()
    print_status(f"LLMè°ƒç”¨å®Œæˆï¼Œè€—æ—¶: {elapsed:.1f}ç§’", "INFO")

    assert summary is not None, "æ‘˜è¦ä¸åº”ä¸ºNone"
    assert 0 <= summary.score <= 100, "è¯„åˆ†åº”åœ¨0-100èŒƒå›´å†…"

    print_status(f"æ¨èè¯„åˆ†: {summary.score}/100", "INFO")
    print_status(f"æ–‡ç« æ‘˜è¦: {summary.summary[:100]}...", "INFO")
    print_status(f"æ¨èç†ç”±: {summary.reason[:80]}...", "INFO")

    print_status("æ–‡ç« æ‘˜è¦ç”Ÿæˆæµ‹è¯•é€šè¿‡", "OK")


@pytest.mark.asyncio
async def test_build_workflow_full(daily_generator, test_markdown_file):
    """æµ‹è¯•å®Œæ•´çš„å·¥ä½œæµï¼ˆä¸»è¦æµ‹è¯•ï¼‰

    âš ï¸ æ­¤æµ‹è¯•ä¼šå¤„ç†æ‰€æœ‰æ–‡ç« å¹¶è°ƒç”¨å¤šæ¬¡LLMï¼Œé¢„è®¡è€—æ—¶2-5åˆ†é’Ÿ
    """
    print_status("=" * 60, "INFO")
    print_status("å¼€å§‹æµ‹è¯•: å®Œæ•´å·¥ä½œæµ", "START")
    print_status("âš ï¸  æ­¤æµ‹è¯•ä¼šå¤„ç†æ‰€æœ‰æ–‡ç« å¹¶å¤šæ¬¡è°ƒç”¨LLM", "WARN")
    print_status("âš ï¸  é¢„è®¡è€—æ—¶ 2-5 åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...", "WARN")
    print_status("=" * 60, "INFO")

    start_time = datetime.now()

    # æ‰§è¡Œå®Œæ•´å·¥ä½œæµ
    await daily_generator.build_workflow(test_markdown_file)

    elapsed = (datetime.now() - start_time).total_seconds()
    print_status(f"å·¥ä½œæµæ‰§è¡Œå®Œæˆï¼Œæ€»è€—æ—¶: {elapsed:.1f}ç§’ ({elapsed/60:.1f}åˆ†é’Ÿ)", "OK")

    # éªŒè¯è¾“å‡ºæ–‡ä»¶
    output_file = Path(
        "output") / f"daily_rich_text_{datetime.now().strftime('%Y%m%d')}.html"

    if output_file.exists():
        print_status(f"è¾“å‡ºæ–‡ä»¶å·²ç”Ÿæˆ: {output_file}", "OK")
        with open(output_file, "r", encoding="utf-8") as f:
            content = f.read()
        print_status(f"è¾“å‡ºæ–‡ä»¶å¤§å°: {len(content)} å­—ç¬¦", "INFO")
    else:
        print_status("æœªç”Ÿæˆè¾“å‡ºæ–‡ä»¶ï¼ˆå¯èƒ½æ˜¯æ–‡ç« è¯„åˆ†éƒ½ä½äº90åˆ†ï¼‰", "WARN")

    print_status("å®Œæ•´å·¥ä½œæµæµ‹è¯•é€šè¿‡", "OK")


def test_run_sync_method(daily_generator, test_markdown_file):
    """æµ‹è¯•åŒæ­¥å…¥å£æ–¹æ³• run()

    âš ï¸ æ­¤æµ‹è¯•ä¸ test_build_workflow_full åŠŸèƒ½ç›¸åŒï¼Œåªæµ‹è¯•ä¸€ä¸ªå³å¯
    """
    print_status("=" * 60, "INFO")
    print_status("å¼€å§‹æµ‹è¯•: åŒæ­¥å…¥å£æ–¹æ³• run()", "START")
    print_status("âš ï¸  æ­¤æµ‹è¯•ä¼šå¤„ç†æ‰€æœ‰æ–‡ç« å¹¶å¤šæ¬¡è°ƒç”¨LLM", "WARN")
    print_status("âš ï¸  é¢„è®¡è€—æ—¶ 2-5 åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...", "WARN")
    print_status("=" * 60, "INFO")

    start_time = datetime.now()

    # è°ƒç”¨åŒæ­¥æ–¹æ³•
    daily_generator.run(test_markdown_file)

    elapsed = (datetime.now() - start_time).total_seconds()
    print_status(f"æ‰§è¡Œå®Œæˆï¼Œæ€»è€—æ—¶: {elapsed:.1f}ç§’ ({elapsed/60:.1f}åˆ†é’Ÿ)", "OK")
    print_status("åŒæ­¥æ–¹æ³•æµ‹è¯•é€šè¿‡", "OK")


# ========== ç›´æ¥è¿è¡Œè„šæœ¬æ—¶çš„å…¥å£ ==========
if __name__ == "__main__":
    """
    ç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶è¿›è¡Œæµ‹è¯•

    ä½¿ç”¨æ–¹æ³•:
        uv run python tests/test_daily_generate_workflow.py
    """
    print("\n" + "=" * 60)
    print("ğŸ§ª æ¯æ—¥æ—¥æŠ¥ç”Ÿæˆå™¨å·¥ä½œæµæµ‹è¯•")
    print("=" * 60 + "\n")

    # è®¾ç½®æµ‹è¯•æ–‡ä»¶è·¯å¾„
    project_root = Path(__file__).parent.parent
    test_file = project_root / "output" / "articles_20260119.md"

    if not test_file.exists():
        print_status(f"æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_file}", "ERROR")
        sys.exit(1)

    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    if not os.getenv("DASHSCOPE_API_KEY"):
        print_status("æœªè®¾ç½® DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡", "ERROR")
        print_status(
            "è¯·è®¾ç½®ç¯å¢ƒå˜é‡: export DASHSCOPE_API_KEY='your_api_key'", "INFO")
        sys.exit(1)

    print_status(f"æµ‹è¯•æ–‡ä»¶: {test_file}", "INFO")
    print_status(f"ç¯å¢ƒå˜é‡ DASHSCOPE_API_KEY: å·²è®¾ç½®", "OK")

    # åˆ›å»ºç”Ÿæˆå™¨
    print_status("æ­£åœ¨åˆå§‹åŒ– DailyGenerator...", "WAIT")
    generator = DailyGenerator(
        model="qwen-plus",
        enable_thinking=True,
        thinking_budget=1024,
        max_retries=2
    )
    print_status("DailyGenerator åˆå§‹åŒ–å®Œæˆ", "OK")

    # æ­¥éª¤1: æµ‹è¯•è§£ææ–‡ç« é“¾æ¥
    print("\n" + "-" * 40)
    print_status("æ­¥éª¤ 1/4: è§£ææ–‡ç« é“¾æ¥", "START")
    urls = generator._parse_article_urls(str(test_file))
    print_status(f"è§£æåˆ° {len(urls)} ä¸ªæ–‡ç« é“¾æ¥", "OK")
    for i, url in enumerate(urls, 1):
        print_status(f"  {i}. {url}", "INFO")

    # æ­¥éª¤2: æµ‹è¯•è·å–HTMLå†…å®¹
    print("\n" + "-" * 40)
    print_status("æ­¥éª¤ 2/4: è·å–ç¬¬ä¸€ç¯‡æ–‡ç« HTMLå†…å®¹", "START")
    print_status("æ­£åœ¨è¯·æ±‚ç½‘é¡µ...", "WAIT")
    html_content = generator._get_html_content(urls[0])
    print_status(f"HTMLå†…å®¹é•¿åº¦: {len(html_content)} å­—ç¬¦", "OK")

    # æ­¥éª¤3: æµ‹è¯•æå–å…ƒæ•°æ®
    print("\n" + "-" * 40)
    print_status("æ­¥éª¤ 3/4: æå–æ–‡ç« å…ƒæ•°æ®", "START")
    metadata = generator._extract_article_metadata(html_content, urls[0])
    print_status(f"æ ‡é¢˜: {metadata.title}", "INFO")
    print_status(f"å…¬ä¼—å·: {metadata.account_name}", "INFO")
    print_status(f"å‘å¸ƒæ—¶é—´: {metadata.publish_time}", "INFO")
    print_status(f"æ­£æ–‡é•¿åº¦: {len(metadata.content)} å­—ç¬¦", "OK")

    # æ­¥éª¤4: è¿è¡Œå®Œæ•´å·¥ä½œæµ
    print("\n" + "-" * 40)
    print_status("æ­¥éª¤ 4/4: æ‰§è¡Œå®Œæ•´å·¥ä½œæµ", "START")
    print_status("âš ï¸  æ­¤æ­¥éª¤ä¼šå¤„ç†æ‰€æœ‰æ–‡ç« å¹¶å¤šæ¬¡è°ƒç”¨LLM", "WARN")
    print_status("âš ï¸  é¢„è®¡è€—æ—¶ 2-5 åˆ†é’Ÿï¼Œæ¯ç¯‡æ–‡ç« ä¼šæ˜¾ç¤ºè¿›åº¦...", "WARN")
    print("-" * 40 + "\n")

    start_time = datetime.now()
    generator.run(str(test_file))
    elapsed = (datetime.now() - start_time).total_seconds()

    print("\n" + "=" * 60)
    print_status(f"ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼æ€»è€—æ—¶: {elapsed:.1f}ç§’ ({elapsed/60:.1f}åˆ†é’Ÿ)", "END")
    print("=" * 60)

    # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
    output_file = Path(
        "output") / f"daily_rich_text_{datetime.now().strftime('%Y%m%d')}.html"
    if output_file.exists():
        print_status(f"ç”Ÿæˆçš„æ–‡ä»¶: {output_file}", "OK")
    else:
        print_status("æœªç”Ÿæˆè¾“å‡ºæ–‡ä»¶", "WARN")
